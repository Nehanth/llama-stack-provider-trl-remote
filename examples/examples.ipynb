{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# How to Use Llama Stack TRL Remote Provider\n",
    "\n",
    "This notebook demonstrates how to interact with the Llama Stack TRL Remote Provider for post-training tasks, specifically Direct Preference Optimization (DPO). The remote provider allows you to run training jobs on a separate service while managing them through the Llama Stack API.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The TRL Remote Provider enables you to:\n",
    "- Upload preference datasets for remote training\n",
    "- Submit DPO training jobs to remote TRL service\n",
    "- Monitor remote training progress and retrieve artifacts\n",
    "- Manage distributed post-training workflows through a REST API\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure that:\n",
    "1. The TRL Remote Service is running on `http://localhost:8080`\n",
    "2. The Llama Stack client is running on `http://127.0.0.1:8321`\n",
    "3. You have the required dependencies installed\n",
    "4. The client is configured with the remote TRL provider\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by importing the required libraries and setting up our API configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "\n",
    "# Base URL for the Llama Stack client API\n",
    "# The client connects to the remote TRL service for training\n",
    "base_url = \"http://127.0.0.1:8321\"\n",
    "\n",
    "# Remote TRL service runs on http://localhost:8080\n",
    "# Client forwards training requests to the remote service\n",
    "remote_service_url = \"http://localhost:8080\"\n",
    "\n",
    "# Headers for GET requests (retrieving data)\n",
    "headers_get = {\n",
    "    \"accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Headers for POST requests (sending data)\n",
    "headers_post = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Check Available Providers\n",
    "\n",
    "First, let's verify that our remote TRL provider is properly configured and available. This endpoint will show us all the providers that are currently registered with the Llama Stack client, including the remote TRL provider configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'api': 'post_training', 'provider_id': 'trl_remote', 'provider_type': 'remote::trl', 'config': {'base_url': 'http://localhost:8080', 'timeout': 3600, 'connect_timeout': 30, 'max_retries': 3, 'retry_delay': 5, 'training_config': {'device': 'cuda', 'dpo_beta': 0.1, 'dpo_loss_type': 'sigmoid', 'use_reference_model': True, 'max_seq_length': 2048, 'gradient_checkpointing': False, 'logging_steps': 10, 'warmup_ratio': 0.1, 'weight_decay': 0.01}}, 'health': {'status': 'Not Implemented', 'message': 'Provider does not implement health check'}}, {'api': 'datasetio', 'provider_id': 'localfs', 'provider_type': 'inline::localfs', 'config': {'kvstore': {'type': 'sqlite', 'db_path': '/tmp/llama_stack_provider_trl_remote/datasetio.db'}}, 'health': {'status': 'Not Implemented', 'message': 'Provider does not implement health check'}}]}\n"
     ]
    }
   ],
   "source": [
    "# Get the list of available providers\n",
    "# This will show us what services are available (remote TRL for post-training, localfs for datasets, etc.)\n",
    "\n",
    "url_providers = f\"{base_url}/v1/providers\"\n",
    "response_providers = requests.get(url_providers, headers=headers_get)\n",
    "\n",
    "# Display the providers and their configurations\n",
    "# You should see 'remote::trl' provider for post-training and 'localfs' for dataset storage\n",
    "print(response_providers.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.1 Upload a DPO Dataset\n",
    "\n",
    "Now let's create and upload a preference dataset for remote DPO training. This dataset contains examples of prompts with both \"chosen\" (high-quality) and \"rejected\" (low-quality) responses. When training starts, this dataset will be sent to the remote TRL service for processing.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- `prompt`: The input question or instruction\n",
    "- `chosen`: The preferred/high-quality response\n",
    "- `rejected`: The less preferred/low-quality response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Upload Status: 200\n",
      "Dataset Upload Response: {'identifier': 'test-dpo-dataset-remote', 'provider_resource_id': 'test-dpo-dataset-remote', 'provider_id': 'localfs', 'type': 'dataset', 'owner': {'principal': '', 'attributes': {}}, 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is 2+2?', 'chosen': '2+2 equals 4. This is basic arithmetic.', 'rejected': \"I don't know math.\"}, {'prompt': 'What color is the sky?', 'chosen': 'The sky is blue during clear weather.', 'rejected': 'No idea about colors.'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Minimal DPO dataset for fast testing'}}\n"
     ]
    }
   ],
   "source": [
    "# Upload a MINIMAL DPO dataset for fast remote training\n",
    "# This creates a tiny preference dataset for rapid testing\n",
    "\n",
    "url_upload_dataset = f\"{base_url}/v1/datasets\"\n",
    "\n",
    "# Define the minimal dataset payload - just 2 examples for speed!\n",
    "dataset_payload = {\n",
    "    \"dataset_id\": \"test-dpo-dataset-remote\",\n",
    "    \"purpose\": \"post-training/messages\",             \n",
    "    \"dataset_type\": \"preference\",                    \n",
    "    \"source\": {\n",
    "        \"type\": \"rows\",                              \n",
    "        \"rows\": [\n",
    "            {\n",
    "                \"prompt\": \"What is 2+2?\",\n",
    "                \"chosen\": \"2+2 equals 4. This is basic arithmetic.\",\n",
    "                \"rejected\": \"I don't know math.\"\n",
    "            },\n",
    "            {\n",
    "                \"prompt\": \"What color is the sky?\",\n",
    "                \"chosen\": \"The sky is blue during clear weather.\",\n",
    "                \"rejected\": \"No idea about colors.\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"provider_id\": \"localfs\", # Use local filesystem storage\n",
    "        \"description\": \"Minimal DPO dataset for fast testing\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Send the POST request to upload the dataset\n",
    "response_dataset = requests.post(url_upload_dataset, headers=headers_post, json=dataset_payload)\n",
    "print(\"Dataset Upload Status:\", response_dataset.status_code)\n",
    "print(\"Dataset Upload Response:\", response_dataset.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.2 Verify Dataset Upload\n",
    "\n",
    "Let's confirm that our dataset was successfully uploaded and is now available in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'identifier': 'test-dpo-dataset-remote', 'provider_resource_id': 'test-dpo-dataset-remote', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is 2+2?', 'chosen': '2+2 equals 4. This is basic arithmetic.', 'rejected': \"I don't know math.\"}, {'prompt': 'What color is the sky?', 'chosen': 'The sky is blue during clear weather.', 'rejected': 'No idea about colors.'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Minimal DPO dataset for fast testing'}}]}\n"
     ]
    }
   ],
   "source": [
    "# Verify that our dataset was successfully uploaded\n",
    "# This should now show our \"test-dpo-dataset-inline-large\" dataset\n",
    "\n",
    "url_datasets = f\"{base_url}/v1/datasets\"\n",
    "response_datasets = requests.get(url_datasets, headers=headers_get)\n",
    "\n",
    "# The response should include our uploaded dataset with all the preference pairs\n",
    "print(response_datasets.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Submitting Remote DPO Training Jobs\n",
    "\n",
    "Now that we have our dataset ready, let's submit a DPO training job to the remote TRL service. The Llama Stack client will forward this request to the remote service running on port 8080, which will execute the actual training.\n",
    "\n",
    "**Key Parameters for Remote Training:**\n",
    "- `model`: The base model to fine-tune (e.g., granite-3.3-2b-base, distilgpt2)  \n",
    "- `algorithm_config`: Native DPO configuration with reward parameters (reward_scale, reward_clip, epsilon, gamma)\n",
    "- `training_config`: Standard training parameters like learning rate, epochs, batch size\n",
    "- `dataset_id`: The preference dataset that will be sent to the remote service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Model Status: 200\n",
      "Train Model Response: {'job_uuid': '1'}\n"
     ]
    }
   ],
   "source": [
    "url_train_model = f\"{base_url}/v1/post-training/preference-optimize\"\n",
    "\n",
    "train_model_data = {\n",
    "    \"job_uuid\": \"2\",\n",
    "    \"finetuned_model\": \"ibm-granite/granite-3.3-2b-instruct\", #smaller - distilgpt2, larger - ibm-granite/granite-3.3-2b-instruct\n",
    "    \n",
    "    #not used for DPO, used for PPO\n",
    "    \"algorithm_config\": {\n",
    "        \"reward_scale\": 0.0,            \n",
    "        \"reward_clip\": 0.0,            \n",
    "        \"epsilon\": 0.0,                 \n",
    "        \"gamma\": 0.0,                 \n",
    "        \n",
    "        #used for DPO (already in run.yaml config)\n",
    "        #\"beta\": 0.1, # controls the strength of the DPO loss                   \n",
    "        #\"loss_type\": \"sigmoid\", # specides the loss function used for DPO       \n",
    "    },\n",
    "    \n",
    "    \"training_config\": {    \n",
    "        \"n_epochs\": 3, # number of epochs to train for\n",
    "        \"max_steps_per_epoch\": 50, # maximum number of steps per epoch\n",
    "        \"gradient_accumulation_steps\": 1, # number of gradient accumulation steps\n",
    "        \n",
    "        \"optimizer_config\": {\n",
    "            \"optimizer_type\": \"adamw\", # adaptive learning with weight decay\n",
    "            \"weight_decay\": 0.01, # prevents overfitting\n",
    "            \"num_warmup_steps\": 0,\n",
    "            \"lr\": 5e-5, # controls how big of a step optimzer is going to take\n",
    "            \"warmup_ratio\": 0.1, # controls how long the optimzer will warmup for\n",
    "        },\n",
    "        \n",
    "        \"data_config\": {\n",
    "            \"data_format\": \"instruct\", # instruct format is used for my preference dataset\n",
    "            \"dataset_id\": \"test-dpo-dataset-remote\",  # my preference dataset\n",
    "            \"batch_size\": 2, # batch size\n",
    "            \"train_split_percentage\": 0.9, # split percentage for training and validation\n",
    "            \"shuffle\": True, # shuffle the dataset\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"hyperparam_search_config\": {},\n",
    "    \"logger_config\": {}\n",
    "}\n",
    "\n",
    "# Make the training request\n",
    "response_train_model = requests.post(url_train_model, headers=headers_post, json=train_model_data)\n",
    "print(\"Train Model Status:\", response_train_model.status_code)\n",
    "print(\"Train Model Response:\", response_train_model.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Monitoring Remote Training Jobs\n",
    "\n",
    "Once a remote training job is submitted, you can monitor its progress through the Llama Stack client. The client communicates with the remote TRL service to get job status and artifacts. Training jobs go through various states: `scheduled`, `in_progress`, `completed`, or `failed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all post-training jobs\n",
    "# This will show all training jobs that have been submitted to the system\n",
    "\n",
    "url_post_training_jobs = f\"{base_url}/v1/post-training/jobs\"\n",
    "response_post_training_jobs = requests.get(url_post_training_jobs, headers=headers_get)\n",
    "\n",
    "# Display all jobs with their current status and metadata\n",
    "print(response_post_training_jobs.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.1 Check Specific Job Status\n",
    "\n",
    "You can get detailed information about a specific training job using its job UUID. This is useful for monitoring progress and checking when training is complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of a specific training job\n",
    "# Replace the job_uuid with the actual UUID from your training job\n",
    "\n",
    "job_uuid = \"dpo-model-demo-remote-live\"  # The job UUID from the remote training request\n",
    "url_job_status = f\"{base_url}/v1/post-training/job/status?job_uuid={job_uuid}\"\n",
    "\n",
    "response_job_status = requests.get(url_job_status, headers=headers_get)\n",
    "\n",
    "print(\"Job Status:\", response_job_status.status_code)\n",
    "# The response will include: status, scheduled_at, started_at, completed_at, checkpoints\n",
    "print(\"Job Status Response:\", response_job_status.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.2 Retrieve Training Artifacts\n",
    "\n",
    "After training is complete (or during training), you can retrieve the artifacts generated by the job, including model checkpoints and training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve artifacts (checkpoints, metrics) from a completed training job\n",
    "# This will show available model checkpoints and their metadata\n",
    "\n",
    "url_job_artifacts = f\"{base_url}/v1/post-training/job/artifacts?job_uuid={job_uuid}\"\n",
    "response_job_artifacts = requests.get(url_job_artifacts, headers=headers_get)\n",
    "\n",
    "print(\"Job Artifacts Status:\", response_job_artifacts.status_code)\n",
    "# The response will include checkpoint information: identifier, path, epoch, training_metrics\n",
    "print(\"Job Artifacts Response:\", response_job_artifacts.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete workflow for using the Llama Stack TRL Remote Provider:\n",
    "\n",
    "1. **Setup**: Configure API endpoints for client and remote service\n",
    "2. **Provider Verification**: Check that remote TRL and localfs providers are available\n",
    "3. **Dataset Management**: Upload preference datasets for remote DPO training\n",
    "4. **Remote Training**: Submit DPO training jobs to remote TRL service\n",
    "5. **Job Monitoring**: Track remote training progress and status\n",
    "6. **Artifact Retrieval**: Access trained model checkpoints and metrics from remote service\n",
    "\n",
    "### Remote Provider Architecture\n",
    "\n",
    "Client Request -> Llama Stack (8321) -> Remote TRL Service (8080) -> DPO Training\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
