{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "\n",
    "# Base URL for the Llama Stack client API\n",
    "# The client connects to the remote TRL service for training\n",
    "base_url = \"http://127.0.0.1:8321\"\n",
    "\n",
    "# Remote TRL service runs on http://localhost:8080\n",
    "# Client forwards training requests to the remote service\n",
    "remote_service_url = \"http://localhost:8080\"\n",
    "\n",
    "# Headers for GET requests (retrieving data)\n",
    "headers_get = {\n",
    "    \"accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Headers for POST requests (sending data)\n",
    "headers_post = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Upload Status: 200\n",
      "Dataset Upload Response: {'identifier': 'test-dpo-dataset-remote-50', 'provider_resource_id': 'test-dpo-dataset-remote-50', 'provider_id': 'localfs', 'type': 'dataset', 'owner': {'principal': '', 'attributes': {}}, 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is machine learning?', 'chosen': 'Machine learning is a branch of AI where algorithms learn from data to make predictions or decisions.', 'rejected': 'Machine learning is just computers doing math stuff.'}, {'prompt': 'Write a hello world program', 'chosen': 'Here is a simple hello world program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```', 'rejected': 'print hello world'}, {'prompt': 'Explain fine-tuning', 'chosen': 'Fine-tuning adapts a pre-trained model to a specific task by additional training on task-specific data.', 'rejected': 'Fine-tuning is training more.'}, {'prompt': 'What is deep learning?', 'chosen': 'Deep learning is a subset of machine learning using neural networks with multiple layers to learn complex patterns.', 'rejected': 'Deep learning is big neural networks.'}, {'prompt': 'Explain supervised learning', 'chosen': 'Supervised learning trains models using labeled datasets where the correct output is provided for each input.', 'rejected': 'Supervised learning means learning with supervision.'}, {'prompt': 'What is unsupervised learning?', 'chosen': 'Unsupervised learning involves training on unlabeled data to discover hidden structures or patterns.', 'rejected': 'Unsupervised learning has no teacher.'}, {'prompt': 'Define reinforcement learning', 'chosen': 'Reinforcement learning trains agents through trial and error by rewarding desirable actions and penalizing mistakes.', 'rejected': 'Reinforcement learning is learning by doing stuff.'}, {'prompt': 'Explain overfitting', 'chosen': 'Overfitting occurs when a model learns the training data too well, including its noise, reducing its generalization on new data.', 'rejected': 'Overfitting means memorizing the data.'}, {'prompt': 'What is natural language processing?', 'chosen': 'Natural language processing enables computers to understand, interpret, and generate human language.', 'rejected': 'NLP is about computers talking.'}, {'prompt': 'Explain gradient descent', 'chosen': 'Gradient descent is an optimization algorithm that iteratively updates model parameters to minimize loss by moving in the direction of the negative gradient.', 'rejected': 'Gradient descent moves the model slowly to better values.'}, {'prompt': 'Explain transfer learning', 'chosen': 'Transfer learning leverages knowledge from a pre-trained model to solve a related task with less data and computation.', 'rejected': 'Transfer learning copies models to new tasks.'}, {'prompt': 'What is computer vision?', 'chosen': 'Computer vision allows machines to interpret and analyze visual information from the world.', 'rejected': 'Computer vision is machines looking at stuff.'}, {'prompt': 'What is artificial general intelligence?', 'chosen': 'Artificial general intelligence refers to highly autonomous systems that can outperform humans at most economically valuable work.', 'rejected': 'AGI is AI that can do everything.'}, {'prompt': 'What is data augmentation?', 'chosen': 'Data augmentation artificially increases the size of training data by generating modified versions of existing data.', 'rejected': 'Data augmentation makes more data.'}, {'prompt': 'Explain tokenization', 'chosen': 'Tokenization is the process of breaking text into smaller units, such as words or subwords, to prepare it for model processing.', 'rejected': 'Tokenization cuts up sentences.'}, {'prompt': 'Explain large language models', 'chosen': 'Large language models are trained on massive datasets and can generate coherent text and understand complex language patterns.', 'rejected': 'LLMs are just huge models that write stuff.'}, {'prompt': 'What is a transformer model?', 'chosen': 'Transformer models use self-attention mechanisms to process input sequences in parallel, enabling efficient and scalable learning.', 'rejected': 'Transformers are big models that pay attention.'}, {'prompt': 'Explain self-attention', 'chosen': 'Self-attention allows a model to weigh different parts of the input sequence when processing a token, enabling better context understanding.', 'rejected': 'Self-attention looks at itself.'}, {'prompt': 'What is zero-shot learning?', 'chosen': \"Zero-shot learning allows models to handle tasks they weren't explicitly trained on by leveraging general knowledge.\", 'rejected': 'Zero-shot means no training needed.'}, {'prompt': 'What is prompt engineering?', 'chosen': 'Prompt engineering involves crafting input prompts to elicit desired responses from language models.', 'rejected': 'Prompt engineering is asking the model stuff.'}, {'prompt': 'Explain hallucination in LLMs', 'chosen': 'Hallucination refers to language models generating plausible-sounding but factually incorrect or fabricated outputs.', 'rejected': 'Hallucination is making up stuff.'}, {'prompt': 'What is alignment in AI?', 'chosen': 'AI alignment ensures models behave in ways that match human values and intentions.', 'rejected': 'Alignment is making AI not dangerous.'}, {'prompt': 'What is multi-modal AI?', 'chosen': 'Multi-modal AI can process and reason across multiple types of data like text, images, audio, and video.', 'rejected': 'Multi-modal AI does many things at once.'}, {'prompt': 'Explain RAG (retrieval-augmented generation)', 'chosen': 'RAG combines retrieval from knowledge bases with generative models to improve factual accuracy in outputs.', 'rejected': 'RAG gets facts from search.'}, {'prompt': 'What is LoRA?', 'chosen': 'LoRA is a fine-tuning technique that adds trainable low-rank matrices to pre-trained model weights, enabling efficient adaptation.', 'rejected': 'LoRA is small changes to big models.'}, {'prompt': 'What is quantization?', 'chosen': 'Quantization reduces model size and speeds up inference by representing weights with lower-precision numbers.', 'rejected': 'Quantization makes models smaller.'}, {'prompt': 'What is model distillation?', 'chosen': 'Distillation transfers knowledge from a large model to a smaller one, preserving performance while reducing size and computation.', 'rejected': 'Distillation is shrinking models.'}, {'prompt': 'Explain chain-of-thought prompting', 'chosen': 'Chain-of-thought prompting encourages models to explain reasoning steps before answering, improving accuracy on complex tasks.', 'rejected': 'It makes the model think out loud.'}, {'prompt': 'Explain temperature in language models', 'chosen': 'Temperature controls randomness in model output â€” higher values generate more diverse responses, lower values make outputs more deterministic.', 'rejected': 'Temperature makes answers more random.'}, {'prompt': 'What is top-k sampling?', 'chosen': 'Top-k sampling limits token selection to the k most probable tokens, reducing randomness and improving output quality.', 'rejected': 'Top-k picks from the best options.'}, {'prompt': 'What is beam search?', 'chosen': 'Beam search explores multiple output sequences simultaneously, selecting the most probable complete sequence.', 'rejected': 'Beam search tries several paths.'}, {'prompt': 'What is token limit?', 'chosen': 'Token limit refers to the maximum number of tokens a model can process in a single input or output sequence.', 'rejected': 'Token limit is how long the model can read.'}, {'prompt': 'What is RLHF?', 'chosen': 'Reinforcement Learning with Human Feedback fine-tunes models by optimizing based on human preference scores.', 'rejected': 'RLHF is when humans give feedback.'}, {'prompt': 'Explain pre-training vs fine-tuning', 'chosen': 'Pre-training involves general unsupervised learning on large corpora; fine-tuning adapts models to specific tasks using supervised data.', 'rejected': 'Pre-training is first, fine-tuning is second.'}, {'prompt': 'What is a reward model?', 'chosen': 'A reward model predicts the desirability of model outputs and guides optimization during preference-based training.', 'rejected': 'Reward model gives scores.'}, {'prompt': 'What is synthetic data?', 'chosen': 'Synthetic data is artificially generated data that mimics real-world data, often used to augment training datasets.', 'rejected': 'Synthetic data is fake data.'}, {'prompt': 'Explain few-shot learning', 'chosen': 'Few-shot learning enables models to generalize to new tasks with very few examples by leveraging prior knowledge.', 'rejected': 'Few-shot is learning from a few examples.'}, {'prompt': 'What is model drift?', 'chosen': \"Model drift occurs when a model's performance degrades over time due to changes in data distributions.\", 'rejected': 'Model drift means the model gets worse.'}, {'prompt': 'Explain evaluation benchmarks', 'chosen': 'Evaluation benchmarks provide standardized tasks to assess model performance across various domains.', 'rejected': 'Benchmarks test models.'}, {'prompt': 'What is instruction tuning?', 'chosen': 'Instruction tuning fine-tunes models to follow explicit natural language instructions for better task generalization.', 'rejected': 'Instruction tuning teaches models to follow commands.'}, {'prompt': 'Explain safety in LLM deployment', 'chosen': 'Safety in LLM deployment involves techniques to prevent harmful, biased, or dangerous outputs.', 'rejected': 'Safety means not letting AI say bad stuff.'}, {'prompt': 'What is multi-turn dialogue?', 'chosen': 'Multi-turn dialogue refers to conversations where the model maintains context across multiple user interactions.', 'rejected': 'Multi-turn is talking back and forth.'}, {'prompt': 'What is hallucination detection?', 'chosen': 'Hallucination detection methods aim to identify when a model generates factually incorrect outputs.', 'rejected': 'It spots made up stuff.'}, {'prompt': 'What is model alignment research?', 'chosen': 'Model alignment research focuses on ensuring AI systems behave consistently with human values and goals.', 'rejected': 'Alignment research makes AI safe.'}, {'prompt': 'What is model interpretability?', 'chosen': 'Interpretability involves techniques that make model decisions understandable to humans.', 'rejected': 'Interpretability explains what AI is doing.'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Expanded DPO preference dataset with 50 examples'}}\n"
     ]
    }
   ],
   "source": [
    "# Upload a DPO dataset for remote training\n",
    "# This creates a preference dataset that will be sent to the remote TRL service\n",
    "\n",
    "url_upload_dataset = f\"{base_url}/v1/datasets\"\n",
    "\n",
    "# Define the dataset payload with preference pairs\n",
    "dataset_payload = {\n",
    "    \"dataset_id\": \"test-dpo-dataset-remote-50\",\n",
    "    \"purpose\": \"post-training/messages\",             \n",
    "    \"dataset_type\": \"preference\",                    \n",
    "    \"source\": {\n",
    "        \"type\": \"rows\",                              \n",
    "        \"rows\": [\n",
    "            {\"prompt\": \"What is machine learning?\", \"chosen\": \"Machine learning is a branch of AI where algorithms learn from data to make predictions or decisions.\", \"rejected\": \"Machine learning is just computers doing math stuff.\"},\n",
    "            {\"prompt\": \"Write a hello world program\", \"chosen\": \"Here is a simple hello world program in Python:\\n\\n```python\\nprint(\\\"Hello, World!\\\")\\n```\", \"rejected\": \"print hello world\"},\n",
    "            {\"prompt\": \"Explain fine-tuning\", \"chosen\": \"Fine-tuning adapts a pre-trained model to a specific task by additional training on task-specific data.\", \"rejected\": \"Fine-tuning is training more.\"},\n",
    "            {\"prompt\": \"What is deep learning?\", \"chosen\": \"Deep learning is a subset of machine learning using neural networks with multiple layers to learn complex patterns.\", \"rejected\": \"Deep learning is big neural networks.\"},\n",
    "            {\"prompt\": \"Explain supervised learning\", \"chosen\": \"Supervised learning trains models using labeled datasets where the correct output is provided for each input.\", \"rejected\": \"Supervised learning means learning with supervision.\"},\n",
    "            {\"prompt\": \"What is unsupervised learning?\", \"chosen\": \"Unsupervised learning involves training on unlabeled data to discover hidden structures or patterns.\", \"rejected\": \"Unsupervised learning has no teacher.\"},\n",
    "            {\"prompt\": \"Define reinforcement learning\", \"chosen\": \"Reinforcement learning trains agents through trial and error by rewarding desirable actions and penalizing mistakes.\", \"rejected\": \"Reinforcement learning is learning by doing stuff.\"},\n",
    "            {\"prompt\": \"Explain overfitting\", \"chosen\": \"Overfitting occurs when a model learns the training data too well, including its noise, reducing its generalization on new data.\", \"rejected\": \"Overfitting means memorizing the data.\"},\n",
    "            {\"prompt\": \"What is natural language processing?\", \"chosen\": \"Natural language processing enables computers to understand, interpret, and generate human language.\", \"rejected\": \"NLP is about computers talking.\"},\n",
    "            {\"prompt\": \"Explain gradient descent\", \"chosen\": \"Gradient descent is an optimization algorithm that iteratively updates model parameters to minimize loss by moving in the direction of the negative gradient.\", \"rejected\": \"Gradient descent moves the model slowly to better values.\"},\n",
    "            {\"prompt\": \"Explain transfer learning\", \"chosen\": \"Transfer learning leverages knowledge from a pre-trained model to solve a related task with less data and computation.\", \"rejected\": \"Transfer learning copies models to new tasks.\"},\n",
    "            {\"prompt\": \"What is computer vision?\", \"chosen\": \"Computer vision allows machines to interpret and analyze visual information from the world.\", \"rejected\": \"Computer vision is machines looking at stuff.\"},\n",
    "            {\"prompt\": \"What is artificial general intelligence?\", \"chosen\": \"Artificial general intelligence refers to highly autonomous systems that can outperform humans at most economically valuable work.\", \"rejected\": \"AGI is AI that can do everything.\"},\n",
    "            {\"prompt\": \"What is data augmentation?\", \"chosen\": \"Data augmentation artificially increases the size of training data by generating modified versions of existing data.\", \"rejected\": \"Data augmentation makes more data.\"},\n",
    "            {\"prompt\": \"Explain tokenization\", \"chosen\": \"Tokenization is the process of breaking text into smaller units, such as words or subwords, to prepare it for model processing.\", \"rejected\": \"Tokenization cuts up sentences.\"},\n",
    "            {\"prompt\": \"Explain large language models\", \"chosen\": \"Large language models are trained on massive datasets and can generate coherent text and understand complex language patterns.\", \"rejected\": \"LLMs are just huge models that write stuff.\"},\n",
    "            {\"prompt\": \"What is a transformer model?\", \"chosen\": \"Transformer models use self-attention mechanisms to process input sequences in parallel, enabling efficient and scalable learning.\", \"rejected\": \"Transformers are big models that pay attention.\"},\n",
    "            {\"prompt\": \"Explain self-attention\", \"chosen\": \"Self-attention allows a model to weigh different parts of the input sequence when processing a token, enabling better context understanding.\", \"rejected\": \"Self-attention looks at itself.\"},\n",
    "            {\"prompt\": \"What is zero-shot learning?\", \"chosen\": \"Zero-shot learning allows models to handle tasks they weren't explicitly trained on by leveraging general knowledge.\", \"rejected\": \"Zero-shot means no training needed.\"},\n",
    "            {\"prompt\": \"What is prompt engineering?\", \"chosen\": \"Prompt engineering involves crafting input prompts to elicit desired responses from language models.\", \"rejected\": \"Prompt engineering is asking the model stuff.\"},\n",
    "            {\"prompt\": \"Explain hallucination in LLMs\", \"chosen\": \"Hallucination refers to language models generating plausible-sounding but factually incorrect or fabricated outputs.\", \"rejected\": \"Hallucination is making up stuff.\"},\n",
    "            {\"prompt\": \"What is alignment in AI?\", \"chosen\": \"AI alignment ensures models behave in ways that match human values and intentions.\", \"rejected\": \"Alignment is making AI not dangerous.\"},\n",
    "            {\"prompt\": \"What is multi-modal AI?\", \"chosen\": \"Multi-modal AI can process and reason across multiple types of data like text, images, audio, and video.\", \"rejected\": \"Multi-modal AI does many things at once.\"},\n",
    "            {\"prompt\": \"Explain RAG (retrieval-augmented generation)\", \"chosen\": \"RAG combines retrieval from knowledge bases with generative models to improve factual accuracy in outputs.\", \"rejected\": \"RAG gets facts from search.\"},\n",
    "            {\"prompt\": \"What is LoRA?\", \"chosen\": \"LoRA is a fine-tuning technique that adds trainable low-rank matrices to pre-trained model weights, enabling efficient adaptation.\", \"rejected\": \"LoRA is small changes to big models.\"},\n",
    "            {\"prompt\": \"What is quantization?\", \"chosen\": \"Quantization reduces model size and speeds up inference by representing weights with lower-precision numbers.\", \"rejected\": \"Quantization makes models smaller.\"},\n",
    "            {\"prompt\": \"What is model distillation?\", \"chosen\": \"Distillation transfers knowledge from a large model to a smaller one, preserving performance while reducing size and computation.\", \"rejected\": \"Distillation is shrinking models.\"},\n",
    "            {\"prompt\": \"Explain chain-of-thought prompting\", \"chosen\": \"Chain-of-thought prompting encourages models to explain reasoning steps before answering, improving accuracy on complex tasks.\", \"rejected\": \"It makes the model think out loud.\"},\n",
    "            {\"prompt\": \"Explain temperature in language models\", \"chosen\": \"Temperature controls randomness in model output â€” higher values generate more diverse responses, lower values make outputs more deterministic.\", \"rejected\": \"Temperature makes answers more random.\"},\n",
    "            {\"prompt\": \"What is top-k sampling?\", \"chosen\": \"Top-k sampling limits token selection to the k most probable tokens, reducing randomness and improving output quality.\", \"rejected\": \"Top-k picks from the best options.\"},\n",
    "            {\"prompt\": \"What is beam search?\", \"chosen\": \"Beam search explores multiple output sequences simultaneously, selecting the most probable complete sequence.\", \"rejected\": \"Beam search tries several paths.\"},\n",
    "            {\"prompt\": \"What is token limit?\", \"chosen\": \"Token limit refers to the maximum number of tokens a model can process in a single input or output sequence.\", \"rejected\": \"Token limit is how long the model can read.\"},\n",
    "            {\"prompt\": \"What is RLHF?\", \"chosen\": \"Reinforcement Learning with Human Feedback fine-tunes models by optimizing based on human preference scores.\", \"rejected\": \"RLHF is when humans give feedback.\"},\n",
    "            {\"prompt\": \"Explain pre-training vs fine-tuning\", \"chosen\": \"Pre-training involves general unsupervised learning on large corpora; fine-tuning adapts models to specific tasks using supervised data.\", \"rejected\": \"Pre-training is first, fine-tuning is second.\"},\n",
    "            {\"prompt\": \"What is a reward model?\", \"chosen\": \"A reward model predicts the desirability of model outputs and guides optimization during preference-based training.\", \"rejected\": \"Reward model gives scores.\"},\n",
    "            {\"prompt\": \"What is synthetic data?\", \"chosen\": \"Synthetic data is artificially generated data that mimics real-world data, often used to augment training datasets.\", \"rejected\": \"Synthetic data is fake data.\"},\n",
    "            {\"prompt\": \"Explain few-shot learning\", \"chosen\": \"Few-shot learning enables models to generalize to new tasks with very few examples by leveraging prior knowledge.\", \"rejected\": \"Few-shot is learning from a few examples.\"},\n",
    "            {\"prompt\": \"What is model drift?\", \"chosen\": \"Model drift occurs when a model's performance degrades over time due to changes in data distributions.\", \"rejected\": \"Model drift means the model gets worse.\"},\n",
    "            {\"prompt\": \"Explain evaluation benchmarks\", \"chosen\": \"Evaluation benchmarks provide standardized tasks to assess model performance across various domains.\", \"rejected\": \"Benchmarks test models.\"},\n",
    "            {\"prompt\": \"What is instruction tuning?\", \"chosen\": \"Instruction tuning fine-tunes models to follow explicit natural language instructions for better task generalization.\", \"rejected\": \"Instruction tuning teaches models to follow commands.\"},\n",
    "            {\"prompt\": \"Explain safety in LLM deployment\", \"chosen\": \"Safety in LLM deployment involves techniques to prevent harmful, biased, or dangerous outputs.\", \"rejected\": \"Safety means not letting AI say bad stuff.\"},\n",
    "            {\"prompt\": \"What is multi-turn dialogue?\", \"chosen\": \"Multi-turn dialogue refers to conversations where the model maintains context across multiple user interactions.\", \"rejected\": \"Multi-turn is talking back and forth.\"},\n",
    "            {\"prompt\": \"What is hallucination detection?\", \"chosen\": \"Hallucination detection methods aim to identify when a model generates factually incorrect outputs.\", \"rejected\": \"It spots made up stuff.\"},\n",
    "            {\"prompt\": \"What is model alignment research?\", \"chosen\": \"Model alignment research focuses on ensuring AI systems behave consistently with human values and goals.\", \"rejected\": \"Alignment research makes AI safe.\"},\n",
    "            {\"prompt\": \"What is model interpretability?\", \"chosen\": \"Interpretability involves techniques that make model decisions understandable to humans.\", \"rejected\": \"Interpretability explains what AI is doing.\"}\n",
    "        ]\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"provider_id\": \"localfs\",                    \n",
    "        \"description\": \"Expanded DPO preference dataset with 50 examples\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Send the POST request to upload the dataset\n",
    "response_dataset = requests.post(url_upload_dataset, headers=headers_post, json=dataset_payload)\n",
    "print(\"Dataset Upload Status:\", response_dataset.status_code)\n",
    "print(\"Dataset Upload Response:\", response_dataset.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote Training Status: 200\n",
      "Remote Training Response: {'job_uuid': 'remote-dpo-training-distilgpt2'}\n"
     ]
    }
   ],
   "source": [
    "# Submit DPO training job to remote TRL service\n",
    "\n",
    "url_train_model = f\"{base_url}/v1/post-training/preference-optimize\"\n",
    "\n",
    "train_model_data = {\n",
    "    \"job_uuid\": \"remote-dpo-training-distilgpt2\",\n",
    "    \"model\": \"distilgpt2\",  # Still using smaller model for quicker experiments\n",
    "    \"finetuned_model\": \"dpo-granite-3.3-2b-base-remote\",\n",
    "    \"checkpoint_dir\": \"../dpo_checkpoints\",\n",
    "    \n",
    "    # LoRA config (only for schema validation passthrough - actual provider runs DPO)\n",
    "    \"algorithm_config\": {\n",
    "        \"type\": \"LoRA\",\n",
    "        \"lora_attn_modules\": [\"attn\"],\n",
    "        \"apply_lora_to_mlp\": False,\n",
    "        \"apply_lora_to_output\": False,\n",
    "        \"rank\": 16,\n",
    "        \"alpha\": 32\n",
    "    },\n",
    "\n",
    "    \"training_config\": {    \n",
    "        \"n_epochs\": 3,                           # Increase epochs for better learning\n",
    "        \"max_steps_per_epoch\": 100,              # More steps per epoch for larger dataset\n",
    "        \"gradient_accumulation_steps\": 2,        # Effective batch size = batch_size * accumulation\n",
    "        \"data_config\": {\n",
    "            \"dataset_id\": \"test-dpo-dataset-remote-50\",\n",
    "            \"batch_size\": 4,                     # Bigger batch helps stability\n",
    "            \"shuffle\": True,\n",
    "            \"data_format\": \"instruct\"\n",
    "        },\n",
    "        \"optimizer_config\": {\n",
    "            \"optimizer_type\": \"adamw\",\n",
    "            \"lr\": 5e-5,                          # Higher learning rate works better for DPO\n",
    "            \"lr_scheduler_type\": \"cosine\",       # Cosine often works better for preference optimization\n",
    "            \"warmup_steps\": 50,                  # Better warmup for stability\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"num_warmup_steps\": 50\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"hyperparam_search_config\": {},\n",
    "    \"logger_config\": {}\n",
    "}\n",
    "\n",
    "response_train_model = requests.post(url_train_model, headers=headers_post, json=train_model_data)\n",
    "print(\"Remote Training Status:\", response_train_model.status_code)\n",
    "print(\"Remote Training Response:\", response_train_model.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'job_uuid': 'remote-dpo-training-distilgpt2'}]}\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all post-training jobs\n",
    "# This will show all training jobs that have been submitted to the system\n",
    "\n",
    "url_post_training_jobs = f\"{base_url}/v1/post-training/jobs\"\n",
    "response_post_training_jobs = requests.get(url_post_training_jobs, headers=headers_get)\n",
    "\n",
    "# Display all jobs with their current status and metadata\n",
    "print(response_post_training_jobs.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status: 200\n",
      "Job Status Response: {'job_uuid': 'remote-dpo-training-distilgpt2', 'status': 'in_progress', 'scheduled_at': '2025-06-23T01:21:22.193361Z', 'started_at': '2025-06-23T01:21:22.194889Z', 'completed_at': None, 'resources_allocated': None, 'checkpoints': []}\n"
     ]
    }
   ],
   "source": [
    "# Check the status of a specific training job\n",
    "# Replace the job_uuid with the actual UUID from your training job\n",
    "\n",
    "job_uuid = \"remote-dpo-training-distilgpt2\"  # The job UUID from the remote training request\n",
    "url_job_status = f\"{base_url}/v1/post-training/job/status?job_uuid={job_uuid}\"\n",
    "\n",
    "response_job_status = requests.get(url_job_status, headers=headers_get)\n",
    "\n",
    "print(\"Job Status:\", response_job_status.status_code)\n",
    "# The response will include: status, scheduled_at, started_at, completed_at, checkpoints\n",
    "print(\"Job Status Response:\", response_job_status.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
